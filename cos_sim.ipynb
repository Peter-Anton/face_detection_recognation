{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# Load your pre-trained model for feature extraction\n",
    "loaded_model = load_model('face_rec_acc_plus.h5')\n",
    "\n",
    "# Load the OpenCV face detection model\n",
    "pb_files = \"/Users/peteranton/Desktop/peter/deep learning/lab6/opencv_face_detector_uint8.pb\"\n",
    "pbtxt_files = \"/Users/peteranton/Desktop/peter/deep learning/lab6/opencv_face_detector.pbtxt\"\n",
    "net = cv2.dnn.readNetFromTensorflow(pb_files, pbtxt_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_classified_dataset = 'non_class_data'\n",
    "no_class = os.listdir(non_classified_dataset)\n",
    "print(len(no_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_names = ['Alex Lawther', 'Logan Lerman', 'Maria Pedraza', 'Anthony Mackie', 'Bobby Morley', 'Chris Evans', 'Chris Pratt', \n",
    "                 'Mark Zuckerberg', 'Anne Hathaway', 'Emilia Clarke', 'Cristiano Ronaldo', 'Josh Radnor', 'Henry Cavil', 'Zoe Saldana', \n",
    "                 'Ellen Page', 'Gwyneth Paltrow', 'Natalie Dormer', 'Barbara Palvin', 'Krysten Ritter', 'Elon Musk', 'Leonardo Dicaprio', \n",
    "                 'Bill Gates', 'Elizabeth Olsen', 'Megan Fox', 'Taylor Swift', 'Tom Hiddleston', 'Jeremy Renner', 'Melissa Fumero', 'Robert Downey Jr',\n",
    "                   'Amber Heard', 'Jake Mcdorman', 'Robert De Niro', 'Grant Gustin', 'Jennifer Lawrence', 'Eliza Taylor', 'Scarlett Johansson', \n",
    "                   'Marie Avgeropoulos', 'Brenton Thwaites', 'Adriana Lima', 'Amanda Crew', 'Hugh Jackman', 'Katherine Langford', 'Camila Mendes', 'Selena Gomez', \n",
    "                   'Avril Lavigne', 'Jeff Bezos', 'Jimmy Fallon', 'Christian Bale', 'Shakira Isabel Mebarak', 'Alvaro Morte', 'Lindsey Morgan', 'Zac Efron', \n",
    "                   'Dominic Purcell', 'Barack Obama', 'Tom Holland', 'Emma Stone', 'Tom Hardy', 'Sophie Turner', 'Tuppence Middleton', 'Kiernen Shipka', \n",
    "                   'Andy Samberg', 'Elizabeth Lail', 'Ursula Corbero', 'Chris Hemsworth', 'Penn Badgley', 'Tom Cruise', 'Richard Harmon', 'Brian J. Smith',\n",
    "                     'Neil Patrick Harris', 'Jason Momoa', 'Dwayne Johnson', 'Nadia Hilker', 'Wentworth Miller', 'Pedro Alonso', 'Stephen Amell', \n",
    "                     'Morena Baccarin', 'Inbar Lavi', 'Alycia Dabnem Carey', 'Zendaya', 'Madelaine Petsch', 'Mark Ruffalo', 'Alexandra Daddario', \n",
    "                     'Tom Ellis', 'Morgan Freeman', 'Natalie Portman', 'Emma Watson', 'Sarah Wayne Callies', 'Irina Shayk', 'Ben Affleck', 'Jessica Barden', \n",
    "                     'Brie Larson', 'Rebecca Ferguson', 'Maisie Williams', 'Millie Bobby Brown', 'Lionel Messi', 'Gal Gadot', 'Margot Robbie', 'Katharine Mcphee',\n",
    "                       'Danielle Panabaker', 'Keanu Reeves', 'Johnny Depp', 'Miley Cyrus', 'Rami Malek', 'Rihanna', 'Lili Reinhart']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [08:34<00:00, 15.55it/s]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tqdm\n",
    "no_class_dataset = []\n",
    "sys.stdout = open(os.devnull, 'w')\n",
    "\n",
    "for face_image in tqdm.tqdm(no_class):\n",
    "    image_path = os.path.join(non_classified_dataset, face_image)\n",
    "    image = cv2.imread(image_path)\n",
    "    preprocessed_image = preprocess_input(image)\n",
    "\n",
    "    preprocessed_image = cv2.resize(preprocessed_image, dsize = (160, 160))\n",
    "    preprocessed_image = preprocessed_image.astype(np.float32)/255.0\n",
    "\n",
    "    feature_representation = loaded_model.predict(np.expand_dims(preprocessed_image, axis=0)).flatten()\n",
    "    \n",
    "    no_class_dataset.append(feature_representation)\n",
    "len(no_class_dataset)    \n",
    "sys.stdout = sys.__stdout__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(net, frame):\n",
    "    # Perform face detection\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1.0, (300, 300), [104., 177., 123.], False, False)\n",
    "    net.setInput(blob)\n",
    "    detections = net.forward()\n",
    "\n",
    "    # Process the detections\n",
    "    for i in range(0, detections.shape[2]):\n",
    "        # Get the confidence (probability) of the current detection:\n",
    "        confidence = detections[0, 0, i, 2]\n",
    "        # Only consider detections if confidence is greater than a fixed minimum confidence:\n",
    "        if confidence > 0.9:\n",
    "            # Get the coordinates of the current detection:\n",
    "            box = detections[0, 0, i, 3:7] * np.array([frame.shape[1], frame.shape[0], frame.shape[1], frame.shape[0]])\n",
    "            (startX, startY, endX, endY) = box.astype(\"int\")\n",
    "            # Draw the detection and the confidence:\n",
    "            text = \"{:.3f}%\".format(confidence * 100)\n",
    "            y = startY - 10 if startY - 10 > 10 else startY + 10\n",
    "            cv2.rectangle(frame, (startX, startY), (endX, endY), (255, 0, 0), 3)\n",
    "            cropped_frame = frame[startY:endY, startX:endX]\n",
    "            cv2.putText(frame, text, (startX, y), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "    \n",
    "    return frame,cropped_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def recognize_face_(unknown_face, model, no_class_dataset, person_names, threshold=0.05):\n",
    "    resized_face = cv2.resize(unknown_face, (160, 160))\n",
    "    preprocessed_face = preprocess_input(resized_face)\n",
    "    preprocessed_face = np.expand_dims(preprocessed_face, axis=0)\n",
    "    \n",
    "    predictions = model.predict(preprocessed_face)\n",
    "\n",
    "    predicted_label = np.argmax(predictions)\n",
    "    predicted_name = person_names[predicted_label]\n",
    "\n",
    "    # Compute cosine similarity between predictions and all embeddings in the dataset\n",
    "    similarities = cosine_similarity(predictions, no_class_dataset)\n",
    "\n",
    "    # Find the maximum similarity\n",
    "    max_similarity = np.max(similarities)\n",
    "\n",
    "    # Check if the maximum similarity is above the threshold\n",
    "    if max_similarity > threshold:\n",
    "        return \"Not Classified\"\n",
    "    else:\n",
    "        return predicted_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('no_class_dataset.npy', no_class_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    try:\n",
    "        ret, frame = cap.read()\n",
    "        frame, cropped_frame = detect_faces(net, frame)\n",
    "        inception_input = cv2.resize(cropped_frame, (160, 160))\n",
    "        inception_input = inception_input / 255.0  \n",
    "        image_to_predict = inception_input.reshape(1,160, 160, 3)\n",
    "        prediction = recognize_face_(inception_input, loaded_model, no_class_dataset, person_names)\n",
    "        cv2.putText(frame,prediction, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2)\n",
    "        cv2.imshow('frame', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        break    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
